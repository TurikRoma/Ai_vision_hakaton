import asyncio
import cv2
import torch
from PIL import Image
from pathlib import Path
import time
import re
import json

def yolo_detect_faces(self, image_path):
    """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é YOLO"""
    print("üîç YOLO: –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü...")
    results = self.models['yolo'].predict(
        source=image_path,
        conf=0.7,
        imgsz=640,
        save=False
    )
    
    faces = []
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    for i, result in enumerate(results):
        for j, box in enumerate(result.boxes):
            if int(box.cls[0].item()) == 0:  # –∫–ª–∞—Å—Å 'face'
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                confidence = box.conf[0].item()
                
                # –í—ã—Ä–µ–∑–∞–µ–º –ª–∏—Ü–æ —Å –∑–∞–ø–∞—Å–æ–º
                margin = 20
                h, w = image_rgb.shape[:2]
                x1 = max(0, x1 - margin)
                y1 = max(0, y1 - margin)
                x2 = min(w, x2 + margin)
                y2 = min(h, y2 + margin)
                
                face_crop = image_rgb[y1:y2, x1:x2]
                
                if face_crop.size > 0:
                    faces.append({
                        'crop': face_crop,
                        'bbox': (x1, y1, x2, y2),
                        'confidence': confidence
                    })
                    print(f"   ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ {len(faces)} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f})")
    
    return faces

async def process_with_mobilenet(self, model_name, face_crop):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞ MobileNet –º–æ–¥–µ–ª—å—é"""
    try:
        model_data = self.models[model_name]
        model = model_data['model']
        class_names = model_data['class_names']
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PIL Image –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã
        pil_image = Image.fromarray(face_crop)
        input_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, predicted_class = torch.max(probabilities, 1)
        
        result = {
            'model': model_name,
            'predicted_class': predicted_class.item(),
            'class_name': class_names[predicted_class.item()],
            'confidence': confidence.item(),
            'all_probabilities': probabilities.cpu().numpy()[0]
        }
        
        return result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {model_name}: {e}")
        return {
            'model': model_name,
            'error': str(e)
        }

async def process_face_pipeline(self, face_crop):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω MobileNet –º–æ–¥–µ–ª–µ–π"""
    print("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    pipeline_order = [
        'mobilenet_skin',
        'mobilenet_age', 
        'mobilenet_eyes_darkcircles',
        'mobilenet_eyes_pupils',
        'mobilenet_general'
    ]
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    tasks = []
    for model_name in pipeline_order:
        task = self.process_with_mobilenet(model_name, face_crop)
        tasks.append(task)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(*tasks)
    
    return results

async def process_image(self, image_path):
    """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {Path(image_path).name}")
    start_time = time.time()
    
    # –®–∞–≥ 1: –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü YOLO
    faces = self.yolo_detect_faces(image_path)
    
    if not faces:
        print("‚ùå –õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
        return None
    
    all_results = []
    
    # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω
    for i, face in enumerate(faces):
        print(f"\nüë§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ {i+1}/{len(faces)}...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ª–∏—Ü–∞
        face_results = await self.process_face_pipeline(face['crop'])
        
        result = {
            'face_id': i + 1,
            'bbox': face['bbox'],
            'detection_confidence': face['confidence'],
            'classification_results': face_results
        }
        
        all_results.append(result)
    
    total_time = time.time() - start_time
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    return all_results

def print_results(self, results):
    if not results:
        return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
    
    analysis_text = ""
    
    for result in results:
        analysis_text += f"üë§ –õ–ò–¶–û {result['face_id']}\n"
        analysis_text += f"üìè BBox: {result['bbox']}\n"
        analysis_text += f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏: {result['detection_confidence']:.3f}\n\n"
        
        for classification in result['classification_results']:
            if 'error' in classification:
                analysis_text += f"‚ùå {classification['model']}: {classification['error']}\n"
            else:
                analysis_text += f"‚úÖ {classification['model']}:\n"
                analysis_text += f"   üè∑Ô∏è  –ö–ª–∞—Å—Å: {classification['class_name']}\n"
                analysis_text += f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {classification['confidence']:.3f}\n"
                
                # –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                probs = classification['all_probabilities']
                class_names = self.models[classification['model']]['class_names']
                
                prob_indices = [(prob, idx) for idx, prob in enumerate(probs)]
                prob_indices.sort(reverse=True, key=lambda x: x[0])
                
                analysis_text += "   üìà –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\n"
                for prob, idx in prob_indices[:3]:
                    is_predicted = (idx == classification['predicted_class'])
                    marker = "‚≠ê" if is_predicted else "  "
                    analysis_text += f"      {marker} {class_names[idx]}: {prob:.3f}\n"
                
                analysis_text += "\n"
        
        analysis_text += "‚îÄ" * 50 + "\n\n"
    
    return analysis_text

async def parse_llm_response(self, llm_answer: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å –∏ JSON —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    """
    try:
        # –ò—â–µ–º JSON –≤ —Ç–µ–∫—Å—Ç–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö)
        json_pattern = r'\{[^{}]*"[^"]*"[^{}]*\}'
        json_matches = re.findall(json_pattern, llm_answer)
        
        parameters = {}
        text_content = llm_answer
        
        if json_matches:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π JSON (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Å–∞–º—ã–π –ø–æ–ª–Ω—ã–π)
            json_str = json_matches[-1]
            text_content = llm_answer.replace(json_str, '').strip()
            
            # –û—á–∏—â–∞–µ–º JSON –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            json_str = re.sub(r'^```json\s*|\s*```$', '', json_str).strip()
            
            try:
                parameters = json.loads(json_str)
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—á–∏—Å—Ç–∏—Ç—å –µ—â–µ
                json_str = re.sub(r'[\n\r\t]', '', json_str)
                parameters = json.loads(json_str)
        
        return {
            "analysis_text": text_content,
            "parameters": parameters
        }
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ analysis_text, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        return {
            "analysis_text": llm_answer,
            "parameters": {}
        }