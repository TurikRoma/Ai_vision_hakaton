import asyncio
import cv2
import numpy as np
from ultralytics import YOLO
from torchvision.models import mobilenet_v3_small
import torch.nn as nn
import torch
from PIL import Image
import torchvision.transforms as transforms
from pathlib import Path
import time

from llm_handler import llm_response

class ModelPipeline:
    def __init__(self):
        self.models = {}
        self.device = torch.device('cpu')
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        self.model_configs = {
            'yolo': {
                'path': 'model.pt',
                'type': 'yolo'
            },
            'mobilenet_skin': {
                'path': 'mobilenet_skin.pth',
                'num_classes': 3,
                'class_names': ['acne', 'freckles', 'healthy']
            },
            'mobilenet_age': {
                'path': 'mobilenet_age.pth', 
                'num_classes': 6,
                'class_names': ['adult', 'baby', 'child', 'middle', 'pensioner', 'teenage']
            },
            'mobilenet_eyes_darkcircles': {
                'path': 'mobilenet_darkcircles.pth',
                'num_classes': 3, 
                'class_names': ['darkcircles', 'healthy', 'light_darkcircles']
            },
            'mobilenet_eyes_pupils': {
                'path': 'mobilenet_eyes_pupils.pth',
                'num_classes': 3,
                'class_names': ['conjunctivitis', 'healthy', 'yellowness']
            },
            'mobilenet_general': {
                'path': 'mobilenet_general.pth',
                'num_classes': 2,
                'class_names': ['edema', 'healthy'] 
            }
        }
        
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])

    async def load_yolo_model(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏"""
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏...")
        try:
            self.models['yolo'] = YOLO(self.model_configs['yolo']['path'])
            print("‚úÖ YOLO –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO: {e}")
            raise

    async def load_mobilenet_model(self, model_name):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ MobileNet –º–æ–¥–µ–ª–∏"""
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ {model_name}...")
        try:
            config = self.model_configs[model_name]
            
            model = mobilenet_v3_small(weights=None)
            model.classifier[3] = nn.Linear(
                model.classifier[3].in_features, 
                config['num_classes']
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            checkpoint = torch.load(config['path'], map_location=self.device)
            if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model.to(self.device)
            model.eval()
            
            self.models[model_name] = {
                'model': model,
                'class_names': config['class_names']
            }
            print(f"‚úÖ {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {e}")
            raise

    async def load_all_models(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üöÄ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π...")
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        tasks = []
        tasks.append(self.load_yolo_model())
        
        mobilenet_models = [
            'mobilenet_skin', 'mobilenet_age', 'mobilenet_eyes_darkcircles',
            'mobilenet_eyes_pupils', 'mobilenet_general'
        ]
        
        for model_name in mobilenet_models:
            tasks.append(self.load_mobilenet_model(model_name))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        await asyncio.gather(*tasks)
        
        loading_time = time.time() - start_time
        print(f"üéâ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞ {loading_time:.2f} —Å–µ–∫—É–Ω–¥")

    def yolo_detect_faces(self, image_path):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é YOLO"""
        print("üîç YOLO: –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü...")
        results = self.models['yolo'].predict(
            source=image_path,
            conf=0.7,
            imgsz=640,
            save=False
        )
        
        faces = []
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        for i, result in enumerate(results):
            for j, box in enumerate(result.boxes):
                if int(box.cls[0].item()) == 0:  # –∫–ª–∞—Å—Å 'face'
                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                    confidence = box.conf[0].item()
                    
                    # –í—ã—Ä–µ–∑–∞–µ–º –ª–∏—Ü–æ —Å –∑–∞–ø–∞—Å–æ–º
                    margin = 20
                    h, w = image_rgb.shape[:2]
                    x1 = max(0, x1 - margin)
                    y1 = max(0, y1 - margin)
                    x2 = min(w, x2 + margin)
                    y2 = min(h, y2 + margin)
                    
                    face_crop = image_rgb[y1:y2, x1:x2]
                    
                    if face_crop.size > 0:
                        faces.append({
                            'crop': face_crop,
                            'bbox': (x1, y1, x2, y2),
                            'confidence': confidence
                        })
                        print(f"   ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ {len(faces)} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f})")
        
        return faces

    async def process_with_mobilenet(self, model_name, face_crop):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞ MobileNet –º–æ–¥–µ–ª—å—é"""
        try:
            model_data = self.models[model_name]
            model = model_data['model']
            class_names = model_data['class_names']
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PIL Image –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã
            pil_image = Image.fromarray(face_crop)
            input_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidence, predicted_class = torch.max(probabilities, 1)
            
            result = {
                'model': model_name,
                'predicted_class': predicted_class.item(),
                'class_name': class_names[predicted_class.item()],
                'confidence': confidence.item(),
                'all_probabilities': probabilities.cpu().numpy()[0]
            }
            
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {model_name}: {e}")
            return {
                'model': model_name,
                'error': str(e)
            }

    async def process_face_pipeline(self, face_crop):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω MobileNet –º–æ–¥–µ–ª–µ–π"""
        print("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        pipeline_order = [
            'mobilenet_skin',
            'mobilenet_age', 
            'mobilenet_eyes_darkcircles',
            'mobilenet_eyes_pupils',
            'mobilenet_general'
        ]
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        tasks = []
        for model_name in pipeline_order:
            task = self.process_with_mobilenet(model_name, face_crop)
            tasks.append(task)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks)
        
        return results

    async def process_image(self, image_path):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {Path(image_path).name}")
        start_time = time.time()
        
        # –®–∞–≥ 1: –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü YOLO
        faces = self.yolo_detect_faces(image_path)
        
        if not faces:
            print("‚ùå –õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
            return None
        
        all_results = []
        
        # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω
        for i, face in enumerate(faces):
            print(f"\nüë§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ {i+1}/{len(faces)}...")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ª–∏—Ü–∞
            face_results = await self.process_face_pipeline(face['crop'])
            
            result = {
                'face_id': i + 1,
                'bbox': face['bbox'],
                'detection_confidence': face['confidence'],
                'classification_results': face_results
            }
            
            all_results.append(result)
        
        total_time = time.time() - start_time
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        return all_results

    def print_results(self, results):
        if not results:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        
        analysis_text = ""
        
        for result in results:
            analysis_text += f"üë§ –õ–ò–¶–û {result['face_id']}\n"
            analysis_text += f"üìè BBox: {result['bbox']}\n"
            analysis_text += f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏: {result['detection_confidence']:.3f}\n\n"
            
            for classification in result['classification_results']:
                if 'error' in classification:
                    analysis_text += f"‚ùå {classification['model']}: {classification['error']}\n"
                else:
                    analysis_text += f"‚úÖ {classification['model']}:\n"
                    analysis_text += f"   üè∑Ô∏è  –ö–ª–∞—Å—Å: {classification['class_name']}\n"
                    analysis_text += f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {classification['confidence']:.3f}\n"
                    
                    # –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    probs = classification['all_probabilities']
                    class_names = self.models[classification['model']]['class_names']
                    
                    prob_indices = [(prob, idx) for idx, prob in enumerate(probs)]
                    prob_indices.sort(reverse=True, key=lambda x: x[0])
                    
                    analysis_text += "   üìà –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\n"
                    for prob, idx in prob_indices[:3]:
                        is_predicted = (idx == classification['predicted_class'])
                        marker = "‚≠ê" if is_predicted else "  "
                        analysis_text += f"      {marker} {class_names[idx]}: {prob:.3f}\n"
                    
                    analysis_text += "\n"
            
            analysis_text += "‚îÄ" * 50 + "\n\n"
        
        return analysis_text

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
    pipeline = ModelPipeline()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (–æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ)
    await pipeline.load_all_models()
    
    print("\n" + "="*80)
    print("–°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï")
    print("="*80)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    test_images = ["photo_2_2025-10-11_13-22-51.jpg"]
    
    for image_path in test_images:
        if Path(image_path).exists():
            print(f"\nüìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞: {image_path}")
            results = await pipeline.process_image(image_path)
            text = pipeline.print_results(results)
            print(results)
            answer = await llm_response(text)
            print(answer)
        else:
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    asyncio.run(main())