import asyncio
import time
from pathlib import Path
import re
import json

import cv2
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
from ultralytics import YOLO
from torchvision.models import mobilenet_v3_small

class ModelPipeline:
    def __init__(self):
        self.models = {}
        self.device = torch.device('cpu')
        print(f"Using device: {self.device}")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        self.model_configs = {
            'yolo': {
                'path': 'model.pt',
                'type': 'yolo'
            },
            'mobilenet_skin': {
                'path': 'mobilenet_skin.pth',
                'num_classes': 3,
                'class_names': ['acne', 'freckles', 'healthy']
            },
            'mobilenet_age': {
                'path': 'mobilenet_age.pth', 
                'num_classes': 6,
                'class_names': ['adult', 'baby', 'child', 'middle', 'pensioner', 'teenage']
            },
            'mobilenet_eyes_darkcircles': {
                'path': 'mobilenet_darkcircles.pth',
                'num_classes': 3, 
                'class_names': ['darkcircles', 'healthy', 'light_darkcircles']
            },
            'mobilenet_eyes_pupils': {
                'path': 'mobilenet_eyes_pupils.pth',
                'num_classes': 3,
                'class_names': ['conjunctivitis', 'healthy', 'yellowness']
            },
            'mobilenet_general': {
                'path': 'mobilenet_general.pth',
                'num_classes': 2,
                'class_names': ['edema', 'healthy'] 
            }
        }
        
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])

    async def load_yolo_model(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏"""
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏...")
        try:
            self.models['yolo'] = YOLO(self.model_configs['yolo']['path'])
            print("‚úÖ YOLO –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO: {e}")
            raise

    async def load_mobilenet_model(self, model_name):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ MobileNet –º–æ–¥–µ–ª–∏"""
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ {model_name}...")
        try:
            config = self.model_configs[model_name]
            
            model = mobilenet_v3_small(weights=None)
            model.classifier[3] = nn.Linear(
                model.classifier[3].in_features, 
                config['num_classes']
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            checkpoint = torch.load(config['path'], map_location=self.device)
            if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model.to(self.device)
            model.eval()
            
            self.models[model_name] = {
                'model': model,
                'class_names': config['class_names']
            }
            print(f"‚úÖ {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {e}")
            raise

    async def load_all_models(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üöÄ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π...")
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        tasks = []
        tasks.append(self.load_yolo_model())
        
        mobilenet_models = [
            'mobilenet_skin', 'mobilenet_age', 'mobilenet_eyes_darkcircles',
            'mobilenet_eyes_pupils', 'mobilenet_general'
        ]
        
        for model_name in mobilenet_models:
            tasks.append(self.load_mobilenet_model(model_name))
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        await asyncio.gather(*tasks)
        
        loading_time = time.time() - start_time
        print(f"üéâ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞ {loading_time:.2f} —Å–µ–∫—É–Ω–¥")
        return True
    
    def yolo_detect_faces(self, image_path):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é YOLO"""
        print("üîç YOLO: –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü...")
        results = self.models['yolo'].predict(
            source=image_path,
            conf=0.7,
            imgsz=640,
            save=False
        )
        
        faces = []
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        for i, result in enumerate(results):
            for j, box in enumerate(result.boxes):
                if int(box.cls[0].item()) == 0:  # –∫–ª–∞—Å—Å 'face'
                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                    confidence = box.conf[0].item()
                    
                    # –í—ã—Ä–µ–∑–∞–µ–º –ª–∏—Ü–æ —Å –∑–∞–ø–∞—Å–æ–º
                    margin = 20
                    h, w = image_rgb.shape[:2]
                    x1 = max(0, x1 - margin)
                    y1 = max(0, y1 - margin)
                    x2 = min(w, x2 + margin)
                    y2 = min(h, y2 + margin)
                    
                    face_crop = image_rgb[y1:y2, x1:x2]
                    
                    if face_crop.size > 0:
                        faces.append({
                            'crop': face_crop,
                            'bbox': (x1, y1, x2, y2),
                            'confidence': confidence
                        })
                        print(f"   ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ {len(faces)} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f})")
        
        return faces

    async def process_with_mobilenet(self, model_name, face_crop):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞ MobileNet –º–æ–¥–µ–ª—å—é"""
        try:
            model_data = self.models[model_name]
            model = model_data['model']
            class_names = model_data['class_names']
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PIL Image –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã
            pil_image = Image.fromarray(face_crop)
            input_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidence, predicted_class = torch.max(probabilities, 1)
            
            result = {
                'model': model_name,
                'predicted_class': predicted_class.item(),
                'class_name': class_names[predicted_class.item()],
                'confidence': confidence.item(),
                'all_probabilities': probabilities.cpu().numpy()[0]
            }
            
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {model_name}: {e}")
            return {
                'model': model_name,
                'error': str(e)
            }

    async def process_face_pipeline(self, face_crop):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω MobileNet –º–æ–¥–µ–ª–µ–π"""
        print("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        pipeline_order = [
            'mobilenet_skin',
            'mobilenet_age', 
            'mobilenet_eyes_darkcircles',
            'mobilenet_eyes_pupils',
            'mobilenet_general'
        ]
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        tasks = []
        for model_name in pipeline_order:
            task = self.process_with_mobilenet(model_name, face_crop)
            tasks.append(task)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks)
        
        return results

    async def process_image(self, image_path):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {Path(image_path).name}")
        start_time = time.time()
        
        # –®–∞–≥ 1: –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü YOLO
        faces = self.yolo_detect_faces(image_path)
        
        if not faces:
            print("‚ùå –õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
            return None
        
        all_results = []
        
        # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞ —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω
        for i, face in enumerate(faces):
            print(f"\nüë§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ {i+1}/{len(faces)}...")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ª–∏—Ü–∞
            face_results = await self.process_face_pipeline(face['crop'])
            
            result = {
                'face_id': i + 1,
                'bbox': face['bbox'],
                'detection_confidence': face['confidence'],
                'classification_results': face_results
            }
            
            all_results.append(result)
        
        total_time = time.time() - start_time
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        return all_results

    def print_results(self, results):
        if not results:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        
        analysis_text = ""
        
        for result in results:
            analysis_text += f"üë§ –õ–ò–¶–û {result['face_id']}\n"
            analysis_text += f"üìè BBox: {result['bbox']}\n"
            analysis_text += f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏: {result['detection_confidence']:.3f}\n\n"
            
            for classification in result['classification_results']:
                if 'error' in classification:
                    analysis_text += f"‚ùå {classification['model']}: {classification['error']}\n"
                else:
                    analysis_text += f"‚úÖ {classification['model']}:\n"
                    analysis_text += f"   üè∑Ô∏è  –ö–ª–∞—Å—Å: {classification['class_name']}\n"
                    analysis_text += f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {classification['confidence']:.3f}\n"
                    
                    # –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    probs = classification['all_probabilities']
                    class_names = self.models[classification['model']]['class_names']
                    
                    prob_indices = [(prob, idx) for idx, prob in enumerate(probs)]
                    prob_indices.sort(reverse=True, key=lambda x: x[0])
                    
                    analysis_text += "   üìà –¢–æ–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\n"
                    for prob, idx in prob_indices[:3]:
                        is_predicted = (idx == classification['predicted_class'])
                        marker = "‚≠ê" if is_predicted else "  "
                        analysis_text += f"      {marker} {class_names[idx]}: {prob:.3f}\n"
                    
                    analysis_text += "\n"
            
            analysis_text += "‚îÄ" * 50 + "\n\n"
        
        return analysis_text

    async def parse_llm_response(self, llm_answer: str) -> dict:
        """
        –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å –∏ JSON —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        """
        try:
            # –ò—â–µ–º JSON –≤ —Ç–µ–∫—Å—Ç–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö)
            json_pattern = r'\{[^{}]*"[^"]*"[^{}]*\}'
            json_matches = re.findall(json_pattern, llm_answer)
            
            parameters = {}
            text_content = llm_answer
            
            if json_matches:
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π JSON (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Å–∞–º—ã–π –ø–æ–ª–Ω—ã–π)
                json_str = json_matches[-1]
                text_content = llm_answer.replace(json_str, '').strip()
                
                # –û—á–∏—â–∞–µ–º JSON –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                json_str = re.sub(r'^```json\s*|\s*```$', '', json_str).strip()
                
                try:
                    parameters = json.loads(json_str)
                except json.JSONDecodeError:
                    # –ï—Å–ª–∏ –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—á–∏—Å—Ç–∏—Ç—å –µ—â–µ
                    json_str = re.sub(r'[\n\r\t]', '', json_str)
                    parameters = json.loads(json_str)
            
            return {
                "analysis_text": text_content,
                "parameters": parameters
            }
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ analysis_text, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            return {
                "analysis_text": llm_answer,
                "parameters": {}
            }
